{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### processing inkml as images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import inkml2img_pictures as ink\n",
    "import pickle\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CROHME_test_2011',\n",
       " 'CROHME_training_2011',\n",
       " 'MatricesTest2014',\n",
       " 'MatricesTrain2014',\n",
       " 'testData_2012',\n",
       " 'TestINKML_2013',\n",
       " 'trainData_2012_part1',\n",
       " 'trainData_2012_part2',\n",
       " 'TrainINKML_2013']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually unzip the dataset from Kaggle, and set root_dir to point at it.\n",
    "\n",
    "root_dir = os.path.join(os.getcwd(), 'math', 'handwritten_math_expressions_kaggle')\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folders = [\n",
    "    'CROHME_training_2011',\n",
    "    'trainData_2012_part1',\n",
    "    'trainData_2012_part2',\n",
    "    'TrainINKML_2013'\n",
    "]\n",
    "\n",
    "test_folders = [\n",
    "    'CROHME_test_2011',\n",
    "    'testData_2012',\n",
    "    'TestINKML_2013',\n",
    "]\n",
    "\n",
    "output_dir = os.path.join(os.getcwd(), 'data', 'all_years')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def get_latex_from_inkml(inkml_path, doc_namespace='{http://www.w3.org/2003/InkML}'):\n",
    "    tree = ET.parse(test_inkml_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    latex_labels = [a.text for a in root.findall(doc_namespace + 'annotation') if a.get('type') == 'truth']\n",
    "    \n",
    "    if len(latex_labels) == 0:\n",
    "        raise ValueError('Could not find a latex label.')\n",
    "        \n",
    "    if len(latex_labels) > 1:\n",
    "        raise ValueError('Found multiple latex labels.')\n",
    "    \n",
    "    return latex_labels[0]\n",
    "\n",
    "\n",
    "def get_tokens_from_traces_data(traces_data):\n",
    "    return [t['label'] for t in traces_data]\n",
    "    \n",
    "\n",
    "def process_inkml(inkml_path, dataset_name):\n",
    "    filename = os.path.basename(inkml_path)\n",
    "    img_path = os.path.join(output_dir, dataset_name, 'images', f'{filename}.png')\n",
    "    img_path = os.path.relpath(img_path)\n",
    "\n",
    "    # Generate image from INKML.\n",
    "    ink.inkml2img(inkml_path, output_path=img_path)\n",
    "\n",
    "    # Save trace group / label / other data.\n",
    "    traces_data = ink.get_traces_data(inkml_path)\n",
    "    \n",
    "    if dataset_name == 'train':\n",
    "        tokens = get_tokens_from_traces_data(traces_data)\n",
    "\n",
    "        latex = get_latex_from_inkml(inkml_path)\n",
    "\n",
    "        return {\n",
    "            'traces_data': traces_data,\n",
    "            'tokens': tokens,\n",
    "            'latex': latex,\n",
    "            'img_path': img_path,\n",
    "            'inkml_path': inkml_path\n",
    "        }\n",
    "    elif dataset_name == 'test':\n",
    "        return {\n",
    "            'traces_data': traces_data,\n",
    "            'img_path': img_path,\n",
    "            'inkml_path': inkml_path\n",
    "        }\n",
    "    \n",
    "    raise NotImplementedError(f'Unknown dataset_name \\'{dataset_name}\\'')\n",
    "\n",
    "\n",
    "def build_dataset(folder_names, output_dir, dataset_name):\n",
    "    \"\"\"\n",
    "    Builds a dataset from the INKML files in the given folders.\n",
    "    Output directory structure will be\n",
    "    \n",
    "    <output_dir>:\n",
    "        <dataset_name>:\n",
    "            images - Directory containing PNG files for each INKML file.\n",
    "            <dataset_name>.csv - Dataset in CSV format.\n",
    "            <dataset_name>.pk - Dataset in pickle format.\n",
    "            \n",
    "    \n",
    "    Args:\n",
    "        dataset_name (string): Name of dataset (probably 'train' or 'test').\n",
    "    \"\"\"\n",
    "    \n",
    "    # Make a list of all paths for INKML files in the given folders.\n",
    "    all_inkml_paths = []\n",
    "    for f in folder_names:\n",
    "        folder_path = os.path.join(root_dir, f)\n",
    "        for inkml_file in os.listdir(folder_path):\n",
    "            if inkml_file.endswith('.inkml'):\n",
    "                full_inkml_path = os.path.join(folder_path, inkml_file)\n",
    "                all_inkml_paths.append(full_inkml_path)\n",
    "             \n",
    "            \n",
    "    # Create directory to store dataset / images.\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    \n",
    "    dataset_dir = os.path.join(output_dir, dataset_name)\n",
    "    if not os.path.exists(dataset_dir):\n",
    "        os.mkdir(dataset_dir)\n",
    "    \n",
    "    img_dir = os.path.join(dataset_dir, 'images')\n",
    "    if not os.path.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "    \n",
    "    \n",
    "    # Generate images / trace data for all INKML files. Apparently Python multiprocessing\n",
    "    # is not supported in a notebook environment.\n",
    "    data = []\n",
    "    errors = []\n",
    "    for inkml_path in tqdm(all_inkml_paths):\n",
    "        try:\n",
    "            row = process_inkml(inkml_path, dataset_name)\n",
    "            data.append(row)\n",
    "        except Exception as e:            \n",
    "            errors.append({\n",
    "                'inkml_path': inkml_path,\n",
    "                'error': str(e),\n",
    "            })\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Save data to CSV and pickle.\n",
    "    csv_path = os.path.join(output_dir, dataset_name, f'{dataset_name}.csv')\n",
    "    pd.DataFrame(data).to_csv(csv_path, index=False)\n",
    "    \n",
    "    pickle_path = os.path.join(output_dir, dataset_name, f'{dataset_name}.pickle')\n",
    "    with open(pickle_path, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        \n",
    "    errors_path = os.path.join(output_dir, dataset_name, f'errors.csv')\n",
    "    pd.DataFrame(errors).to_csv(errors_path, index=False)\n",
    "        \n",
    "    print(f'Created dataset \\'{dataset_name}\\' with {len(data)} examples.')\n",
    "    print(f'Encountered {len(errors)} errors while processing.')\n",
    "    print(f'Wrote images to {img_dir}')\n",
    "    print(f'Wrote CSV to {csv_path}')\n",
    "    print(f'Wrote pickle to {pickle_path}')\n",
    "    print(f'Wrote errors to {errors_path}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158b8f5345494527963f83df06cdbcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=11095.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created dataset 'train' with 9510 examples.\n",
      "Encountered 1585 errors while processing.\n",
      "Wrote images to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\train\\images\n",
      "Wrote CSV to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\train\\train.csv\n",
      "Wrote pickle to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\train\\train.pickle\n",
      "Wrote errors to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\train\\errors.csv\n",
      "\n",
      "Wall time: 9min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "build_dataset(folder_names=train_folders, output_dir=output_dir, dataset_name='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4011f6ea906848cea53a1c3dae0c1f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1507.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Created dataset 'test' with 1507 examples.\n",
      "Encountered 0 errors while processing.\n",
      "Wrote images to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\test\\images\n",
      "Wrote CSV to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\test\\test.csv\n",
      "Wrote pickle to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\test\\test.pickle\n",
      "Wrote errors to C:\\Users\\Jamin Chen\\Development\\10617_Project\\data\\all_years\\test\\errors.csv\n",
      "\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "build_dataset(folder_names=test_folders, output_dir=output_dir, dataset_name='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
