{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object_detection_data_prep.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8klcDIcZukRD"
      },
      "source": [
        "Transfer Learning Using https://towardsdatascience.com/building-your-own-object-detector-pytorch-vs-tensorflow-and-how-to-even-get-started-1d314691d4ae tutorial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXsPg6Qkrab4"
      },
      "source": [
        "import pycocotools\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctiNc45Ku7xv"
      },
      "source": [
        "import re\n",
        "cv2.startWindowThread()\n",
        "\n",
        "class ExpressionImageDataset(Dataset):\n",
        "    \"\"\"\n",
        "    An expression-level dataset.\n",
        "    \"\"\"\n",
        "    def __init__(self, pickle_file, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            pickle_file (string): Path to dataset pickle file.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                    on a sample.\n",
        "        \"\"\"\n",
        "        with open(pickle_file, 'rb') as f:\n",
        "            self.df_data = pd.DataFrame(pickle.load(f))\n",
        "            # print(self.df_data['img_path'].iloc[1000])\n",
        "            self.df_data[\"img_path\"] = self.df_data[\"img_path\"].apply(lambda x:\"\\\\\".join(x.split(\"\\\\\")[2:]))\n",
        "            # print(self.df_data['img_path'].iloc[1000])\n",
        "            self.df_data[\"img_path\"] = self.df_data[\"img_path\"].apply(lambda x: \"/content/drive/My Drive/10617 Data/\"  +  re.sub(r'\\\\', \"/\", x))#/10617 Data\n",
        "            #/content/drive/My Drive/10617 Data/train/images\n",
        "            \n",
        "            # print(self.df_data['img_path'].iloc[1000])\n",
        "\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df_data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        row = self.df_data.iloc[idx]\n",
        "                \n",
        "        traces_data = row['traces_data']\n",
        "        img_path = row['img_path']\n",
        "        tokens = row['tokens']\n",
        "        latex = row['latex']\n",
        "        \n",
        "        # print(img_path)\n",
        "        # CV2 will read the image with white being 255 and black being 0, but since\n",
        "        # our token-level training set uses binary arrays to represent images, we\n",
        "        # need to binarize our image here as well.\n",
        "        image_raw = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        image_binarized = cv2.threshold(image_raw, 127, 255, cv2.THRESH_BINARY)[1]\n",
        "        image_bitmap = image_binarized / 255.0\n",
        "        \n",
        "        sample = {\n",
        "            'image': image_binarized,\n",
        "            'image_bitmap': image_bitmap,\n",
        "            'traces_data': traces_data,\n",
        "            'tokens': tokens,\n",
        "            'latex': latex\n",
        "        }\n",
        "        \n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YefeMGO2yPWq"
      },
      "source": [
        "train_exp_path = \"/content/drive/My Drive/10617 Data/train/train.pickle\" #10617 Data\n",
        "test_exp_path = '/content/drive/My Drive/10617 Data/test/test.pickle' #10617 Data/\n",
        "\n",
        "# print('train')\n",
        "train_exp_set = ExpressionImageDataset(train_exp_path)\n",
        "# print('test')\n",
        "test_exp_set = ExpressionImageDataset(test_exp_path)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ci59aTT7yhM6"
      },
      "source": [
        "sample = train_exp_set.__getitem__(15)\n",
        "sample = test_exp_set.__getitem__(15)\n",
        "# /content/drive/My Drive/10617 Data/test/images/KME1G3_0_sub_10.inkml.png"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5Ea0rTYw1Qn",
        "outputId": "3272d8ea-048e-4bc7-bc4d-540a831ff917",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# train_traces_data = train_exp_set[2]['traces_data']\n",
        "test_traces_data = test_exp_set[2]['traces_data']\n",
        "\n",
        "\n",
        "def get_traces_data_stats(traces_data):\n",
        "    all_coords = []\n",
        "    for pattern in traces_data:\n",
        "        for trace in pattern['trace_group']:\n",
        "            all_coords.extend(trace)\n",
        "        \n",
        "    all_coords = np.array(all_coords)\n",
        "    \n",
        "    x_min, y_min = np.min(all_coords, axis=0)\n",
        "    width, height = np.max(all_coords, axis=0) - [x_min, y_min] + 1\n",
        "    \n",
        "    return x_min, y_min, width, height\n",
        "\n",
        "def get_trace_group_bounding_box(trace_group):\n",
        "    all_coords = []\n",
        "    for t in trace_group:\n",
        "        all_coords.extend(t)\n",
        "        \n",
        "    all_coords = np.array(all_coords)\n",
        "    \n",
        "    x_min, y_min = np.min(all_coords, axis=0)\n",
        "    width, height = np.max(all_coords, axis=0) - [x_min, y_min] + 1\n",
        "    \n",
        "    return x_min, y_min, width, height\n",
        "    \n",
        "\n",
        "def draw_traces_data(traces_data):\n",
        "    im_x_min, im_y_min, width, height = get_traces_data_stats(traces_data)\n",
        "    \n",
        "    # Scale the image down.\n",
        "    max_dim = 1000 # Maximum dimension pre-pad.\n",
        "    sf = 1000 / max(height, width)\n",
        "    scaled_height = int(height * sf)\n",
        "    scaled_width = int(width * sf)\n",
        "    \n",
        "    image = np.ones((scaled_height, scaled_width))\n",
        "    \n",
        "    # Draw the traces on the unscaled image.\n",
        "    for pattern in traces_data:\n",
        "        for trace in pattern['trace_group']:\n",
        "            trace = np.array(trace)\n",
        "            trace -= np.array([im_x_min, im_y_min])\n",
        "            trace = (trace.astype(np.float64) * sf).astype(int)\n",
        "            \n",
        "            for coord_idx in range(1, len(trace)):\n",
        "                cv2.line(image, tuple(trace[coord_idx - 1]), tuple(trace[coord_idx]), color=(0), thickness=5)\n",
        "            \n",
        "    # Pad the scaled image.\n",
        "    pad_factor = 0.05\n",
        "    pad_width = ((int(pad_factor * scaled_height), int(pad_factor * scaled_height)), \n",
        "                 (int(pad_factor * scaled_width), int(pad_factor * scaled_width)))\n",
        "    image = np.pad(image, \n",
        "                     pad_width=pad_width, \n",
        "                     mode='constant', \n",
        "                     constant_values=1)\n",
        "    \n",
        "    # Binarize.\n",
        "    image = (image > 0).astype(int) \n",
        "    \n",
        "    # Open CV wants images to be between 0 and 255.\n",
        "    image *= 255\n",
        "    image = image.astype(np.uint8)\n",
        "    \n",
        "    boxes = []\n",
        "    \n",
        "    # Get bounding boxes.\n",
        "    for pattern in traces_data:\n",
        "        trace_group = pattern['trace_group']\n",
        "        rect_x_min, rect_y_min, rect_width, rect_height = get_trace_group_bounding_box(trace_group)\n",
        "        \n",
        "        rect_x_min = (rect_x_min - im_x_min) * sf + pad_width[1][0]\n",
        "        rect_y_min = (rect_y_min - im_y_min) * sf + pad_width[0][0]\n",
        "        \n",
        "        rect_width *= sf\n",
        "        rect_height *= sf\n",
        "        \n",
        "        # Convert bounding box coords to integers.\n",
        "        rect_x_min = int(rect_x_min)\n",
        "        rect_y_min = int(rect_y_min)\n",
        "        rect_width = int(rect_width)\n",
        "        rect_height = int(rect_height)\n",
        "              \n",
        "        # Draw the rectangle.\n",
        "#         image = cv2.rectangle(image, \n",
        "#                               (int(rect_x_min), int(rect_y_min)), \n",
        "#                               (int(rect_x_min + rect_width), int(rect_y_min + rect_height)), \n",
        "#                               (0), \n",
        "#                               5)\n",
        "        \n",
        "        boxes.append((rect_x_min, rect_y_min, rect_x_min + rect_width, rect_y_min + rect_height))\n",
        "    \n",
        "#     plt.imshow(image, cmap='gray')\n",
        "#     plt.show()\n",
        "    \n",
        "    return image, boxes\n",
        "    \n",
        "image, boxes = draw_traces_data(test_traces_data)\n",
        "print(image.shape)\n",
        "print(boxes)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(397, 1100)\n",
            "[(50, 213, 123, 284), (164, 238, 199, 269), (338, 222, 1038, 250), (299, 123, 340, 127), (368, 70, 419, 169), (447, 109, 492, 182), (556, 18, 1049, 193), (656, 86, 711, 169), (746, 68, 773, 123), (779, 157, 806, 159), (862, 98, 916, 176), (937, 135, 983, 174), (995, 146, 1030, 183), (596, 301, 642, 378), (648, 323, 711, 374)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBpTC1I584Pr"
      },
      "source": [
        "### Train and Test data prep for Object recognition:\n",
        "train df output: obj_df.csv\n",
        "\n",
        "test df output: test_obj_recognition_csv.csv\n",
        "\n",
        "Have tokens, labels (ohe), boxes (true values), latex, and numpy images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_m9k-vEB8PC",
        "outputId": "752004b7-5c82-41d5-a521-6cc3a908dde3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "box_list = {}\n",
        "numpy_list = {}\n",
        "possible_errors = {}\n",
        "\n",
        "for i in range(len(train_exp_set.df_data)):\n",
        "  try:\n",
        "    if i %1000 == 0:\n",
        "      print(i)\n",
        "    #get the specific row:\n",
        "    curr_row = train_exp_set[i]\n",
        "    test_traces_data = curr_row['traces_data']\n",
        "    test_tokens = \"\".join(curr_row['tokens'])\n",
        "\n",
        "    #get trace data for row:\n",
        "    image, boxes = draw_traces_data(test_traces_data)\n",
        "\n",
        "    #double check right row:\n",
        "    df_token = \"\".join(train_exp_set.df_data.iloc[i][\"tokens\"])\n",
        "    if test_tokens != df_token: #check to make srue traces same:\n",
        "      possible_errors[i] = True\n",
        "    else:\n",
        "      possible_errors[i] = False\n",
        "    #add to dict regardless\n",
        "\n",
        "    box_list[i] = boxes\n",
        "    numpy_list[i] = image\n",
        "  except:\n",
        "    print(\"error at {}\".format(i))\n",
        "\n",
        "\n",
        "err = possible_errors.values()\n",
        "print(np.sum(list(err))) # #errors"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n",
            "1700\n",
            "1800\n",
            "1900\n",
            "2000\n",
            "2100\n",
            "2200\n",
            "2300\n",
            "2400\n",
            "2500\n",
            "2600\n",
            "2700\n",
            "2800\n",
            "2900\n",
            "3000\n",
            "3100\n",
            "3200\n",
            "3300\n",
            "3400\n",
            "3500\n",
            "3600\n",
            "3700\n",
            "3800\n",
            "3900\n",
            "4000\n",
            "4100\n",
            "4200\n",
            "4300\n",
            "4400\n",
            "4500\n",
            "4600\n",
            "4700\n",
            "4800\n",
            "4900\n",
            "5000\n",
            "5100\n",
            "5200\n",
            "5300\n",
            "5400\n",
            "5500\n",
            "5600\n",
            "5700\n",
            "5800\n",
            "5900\n",
            "6000\n",
            "6100\n",
            "6200\n",
            "6300\n",
            "6400\n",
            "6500\n",
            "6600\n",
            "6700\n",
            "6800\n",
            "6900\n",
            "7000\n",
            "7100\n",
            "7200\n",
            "7300\n",
            "7400\n",
            "7500\n",
            "7600\n",
            "7700\n",
            "7800\n",
            "7900\n",
            "8000\n",
            "8100\n",
            "CPU times: user 1min 19s, sys: 6.43 s, total: 1min 26s\n",
            "Wall time: 1min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRaEGlzp85EX",
        "outputId": "9de662b0-a446-410a-db75-d15d2cdc42e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "box_list = {}\n",
        "numpy_list = {}\n",
        "possible_errors = {}\n",
        "\n",
        "for i in range(len(test_exp_set.df_data)):\n",
        "  try:\n",
        "    if i %100 == 0:\n",
        "      print(i)\n",
        "    #get the specific row:\n",
        "    curr_row = test_exp_set[i]\n",
        "    test_traces_data = curr_row['traces_data']\n",
        "    test_tokens = \"\".join(curr_row['tokens'])\n",
        "\n",
        "    #get trace data for row:\n",
        "    image, boxes = draw_traces_data(test_traces_data)\n",
        "\n",
        "    #double check right row:\n",
        "    df_token = \"\".join(test_exp_set.df_data.iloc[i][\"tokens\"])\n",
        "    if test_tokens != df_token: #check to make srue traces same:\n",
        "      possible_errors[i] = True\n",
        "    else:\n",
        "      possible_errors[i] = False\n",
        "    #add to dict regardless\n",
        "\n",
        "    box_list[i] = boxes\n",
        "    numpy_list[i] = image\n",
        "  except:\n",
        "    print(\"error at {}\".format(i))\n",
        "\n",
        "err = possible_errors.values()\n",
        "print(np.sum(list(err))) # #errors\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "CPU times: user 14.4 s, sys: 1.18 s, total: 15.5 s\n",
            "Wall time: 13min 37s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "If7CE0jaSiYF"
      },
      "source": [
        "import gc \n",
        "#to clear space before\n",
        "gc.collect()\n",
        "\n",
        "#OHE labels\n",
        "from sklearn.preprocessing import OneHotEncoder as OHE\n",
        "\n",
        "#want OHE labels\n",
        "tokens = train_exp_set.df_data[\"tokens\"].sum()\n",
        "ohe_categories = pd.Series(tokens).unique()\n",
        "ohe_categories, len(ohe_categories)\n",
        "\n",
        "handle = \"ignore\" #or error or ignore... maybe ignore is safer\n",
        "\n",
        "ohe = OHE(categories = [np.array(sorted(ohe_categories))],  handle_unknown=handle)\n",
        "\n",
        "ohe_input = train_exp_set.df_data[\"tokens\"].apply(lambda x: ohe.fit_transform(np.array(x).reshape(-1,1)))\n",
        "\n",
        "print(len(ohe.categories_[0]))\n",
        "\n",
        "train_exp_set.df_data[\"true_location\"] = list(box_list.values())\n",
        "train_exp_set.df_data[\"numpy_image\"] = list(numpy_list.values())\n",
        "train_exp_set.df_data[\"labels\"] = ohe_input\n",
        "\n",
        "#xport to csv\n",
        "train_exp_set.df_data.to_csv(\"obj_df.csv\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lcRKJv_lM0FZ"
      },
      "source": [
        "#use same ohe as train:\n",
        "ohe_input = test_exp_set.df_data[\"tokens\"].apply(lambda x: ohe.fit_transform(np.array(x).reshape(-1,1)))\n",
        "print(len(ohe.categories_[0]))\n",
        "\n",
        "test_exp_set.df_data[\"true_location\"] = list(box_list.values())\n",
        "test_exp_set.df_data[\"numpy_image\"] = list(numpy_list.values())\n",
        "test_exp_set.df_data[\"labels\"] = ohe_input\n",
        "\n",
        "#export to csv\n",
        "obj_df = test_exp_set.df_data[[\"tokens\", \"latex\", \"true_location\", \"img_path\", \"numpy_image\", \"labels\"]]\n",
        "obj_df.to_csv(\"test_obj_recognition_csv.csv\")"
      ],
      "execution_count": 22,
      "outputs": []
    }
  ]
}